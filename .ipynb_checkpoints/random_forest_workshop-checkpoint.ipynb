{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch     Fare Cabin\n",
       "0            1         0       3    male  22.0      1      0   7.2500   NaN\n",
       "1            2         1       1  female  38.0      1      0  71.2833   C85\n",
       "2            3         1       3  female  26.0      0      0   7.9250   NaN\n",
       "3            4         1       1  female  35.0      1      0  53.1000  C123\n",
       "4            5         0       3    male  35.0      0      0   8.0500   NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"titanic/train.csv\")\n",
    "test = pd.read_csv(\"titanic/test.csv\")\n",
    "train.drop(columns=['Name','Ticket','Embarked'], inplace=True)\n",
    "test.drop(columns=['Name','Ticket','Embarked'], inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roela\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Roela\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Level\n",
       "0            1         0       3    1  22.0      1      0   7.2500     -1\n",
       "1            2         1       1    0  38.0      1      0  71.2833      0\n",
       "2            3         1       3    0  26.0      0      0   7.9250     -1\n",
       "3            4         1       1    0  35.0      1      0  53.1000      0\n",
       "4            5         0       3    1  35.0      0      0   8.0500     -1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Sex'] = train['Sex'].astype('category')\n",
    "train['Sex'] = train['Sex'].cat.codes\n",
    "train['Level'] = train['Cabin'].astype(str).str[0]\n",
    "train['Level'][train['Level']=='n'] = np.nan\n",
    "train.drop(['Cabin'], axis=1, inplace=True)\n",
    "train['Level'] = pd.factorize(train['Level'])[0]\n",
    "\n",
    "test['Sex'] = test['Sex'].astype('category')\n",
    "test['Sex'] = test['Sex'].cat.codes\n",
    "test['Level'] = test['Cabin'].astype(str).str[0]\n",
    "test['Level'][test['Level']=='n'] = np.nan\n",
    "test.drop(['Cabin'], axis=1, inplace=True)\n",
    "test['Level'] = pd.factorize(test['Level'])[0]\n",
    "# train['Age'] = train['Age'].astype('float')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20779af7048>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(train.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit(train)\n",
    "train_imputed = imp_mean.transform(train)\n",
    "# test_imputed = imp_mean.transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=2, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Level\n",
       "0            1         0       3    1  22.0      1      0   7.2500     -1\n",
       "1            2         1       1    0  38.0      1      0  71.2833      0\n",
       "2            3         1       3    0  26.0      0      0   7.9250     -1\n",
       "3            4         1       1    0  35.0      1      0  53.1000      0\n",
       "4            5         0       3    1  35.0      0      0   8.0500     -1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.\n  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.\n  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.  56.\n  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.  70.\n  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.  84.\n  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.  98.\n  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111. 112.\n 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125. 126.\n 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139. 140.\n 141. 142. 143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153. 154.\n 155. 156. 157. 158. 159. 160. 161. 162. 163. 164. 165. 166. 167. 168.\n 169. 170. 171. 172. 173. 174. 175. 176. 177. 178. 179. 180. 181. 182.\n 183. 184. 185. 186. 187. 188. 189. 190. 191. 192. 193. 194. 195. 196.\n 197. 198. 199. 200. 201. 202. 203. 204. 205. 206. 207. 208. 209. 210.\n 211. 212. 213. 214. 215. 216. 217. 218. 219. 220. 221. 222. 223. 224.\n 225. 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237. 238.\n 239. 240. 241. 242. 243. 244. 245. 246. 247. 248. 249. 250. 251. 252.\n 253. 254. 255. 256. 257. 258. 259. 260. 261. 262. 263. 264. 265. 266.\n 267. 268. 269. 270. 271. 272. 273. 274. 275. 276. 277. 278. 279. 280.\n 281. 282. 283. 284. 285. 286. 287. 288. 289. 290. 291. 292. 293. 294.\n 295. 296. 297. 298. 299. 300. 301. 302. 303. 304. 305. 306. 307. 308.\n 309. 310. 311. 312. 313. 314. 315. 316. 317. 318. 319. 320. 321. 322.\n 323. 324. 325. 326. 327. 328. 329. 330. 331. 332. 333. 334. 335. 336.\n 337. 338. 339. 340. 341. 342. 343. 344. 345. 346. 347. 348. 349. 350.\n 351. 352. 353. 354. 355. 356. 357. 358. 359. 360. 361. 362. 363. 364.\n 365. 366. 367. 368. 369. 370. 371. 372. 373. 374. 375. 376. 377. 378.\n 379. 380. 381. 382. 383. 384. 385. 386. 387. 388. 389. 390. 391. 392.\n 393. 394. 395. 396. 397. 398. 399. 400. 401. 402. 403. 404. 405. 406.\n 407. 408. 409. 410. 411. 412. 413. 414. 415. 416. 417. 418. 419. 420.\n 421. 422. 423. 424. 425. 426. 427. 428. 429. 430. 431. 432. 433. 434.\n 435. 436. 437. 438. 439. 440. 441. 442. 443. 444. 445. 446. 447. 448.\n 449. 450. 451. 452. 453. 454. 455. 456. 457. 458. 459. 460. 461. 462.\n 463. 464. 465. 466. 467. 468. 469. 470. 471. 472. 473. 474. 475. 476.\n 477. 478. 479. 480. 481. 482. 483. 484. 485. 486. 487. 488. 489. 490.\n 491. 492. 493. 494. 495. 496. 497. 498. 499. 500. 501. 502. 503. 504.\n 505. 506. 507. 508. 509. 510. 511. 512. 513. 514. 515. 516. 517. 518.\n 519. 520. 521. 522. 523. 524. 525. 526. 527. 528. 529. 530. 531. 532.\n 533. 534. 535. 536. 537. 538. 539. 540. 541. 542. 543. 544. 545. 546.\n 547. 548. 549. 550. 551. 552. 553. 554. 555. 556. 557. 558. 559. 560.\n 561. 562. 563. 564. 565. 566. 567. 568. 569. 570. 571. 572. 573. 574.\n 575. 576. 577. 578. 579. 580. 581. 582. 583. 584. 585. 586. 587. 588.\n 589. 590. 591. 592. 593. 594. 595. 596. 597. 598. 599. 600. 601. 602.\n 603. 604. 605. 606. 607. 608. 609. 610. 611. 612. 613. 614. 615. 616.\n 617. 618. 619. 620. 621. 622. 623. 624. 625. 626. 627. 628. 629. 630.\n 631. 632. 633. 634. 635. 636. 637. 638. 639. 640. 641. 642. 643. 644.\n 645. 646. 647. 648. 649. 650. 651. 652. 653. 654. 655. 656. 657. 658.\n 659. 660. 661. 662. 663. 664. 665. 666. 667. 668. 669. 670. 671. 672.\n 673. 674. 675. 676. 677. 678. 679. 680. 681. 682. 683. 684. 685. 686.\n 687. 688. 689. 690. 691. 692. 693. 694. 695. 696. 697. 698. 699. 700.\n 701. 702. 703. 704. 705. 706. 707. 708. 709. 710. 711. 712. 713. 714.\n 715. 716. 717. 718. 719. 720. 721. 722. 723. 724. 725. 726. 727. 728.\n 729. 730. 731. 732. 733. 734. 735. 736. 737. 738. 739. 740. 741. 742.\n 743. 744. 745. 746. 747. 748. 749. 750. 751. 752. 753. 754. 755. 756.\n 757. 758. 759. 760. 761. 762. 763. 764. 765. 766. 767. 768. 769. 770.\n 771. 772. 773. 774. 775. 776. 777. 778. 779. 780. 781. 782. 783. 784.\n 785. 786. 787. 788. 789. 790. 791. 792. 793. 794. 795. 796. 797. 798.\n 799. 800. 801. 802. 803. 804. 805. 806. 807. 808. 809. 810. 811. 812.\n 813. 814. 815. 816. 817. 818. 819. 820. 821. 822. 823. 824. 825. 826.\n 827. 828. 829. 830. 831. 832. 833. 834. 835. 836. 837. 838. 839. 840.\n 841. 842. 843. 844. 845. 846. 847. 848. 849. 850. 851. 852. 853. 854.\n 855. 856. 857. 858. 859. 860. 861. 862. 863. 864. 865. 866. 867. 868.\n 869. 870. 871. 872. 873. 874. 875. 876. 877. 878. 879. 880. 881. 882.\n 883. 884. 885. 886. 887. 888. 889. 890. 891.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-24c61536399e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# features = ('PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Level')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \"\"\"\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    538\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.\n  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.\n  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.  56.\n  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.  70.\n  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.  84.\n  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.  98.\n  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111. 112.\n 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125. 126.\n 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139. 140.\n 141. 142. 143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153. 154.\n 155. 156. 157. 158. 159. 160. 161. 162. 163. 164. 165. 166. 167. 168.\n 169. 170. 171. 172. 173. 174. 175. 176. 177. 178. 179. 180. 181. 182.\n 183. 184. 185. 186. 187. 188. 189. 190. 191. 192. 193. 194. 195. 196.\n 197. 198. 199. 200. 201. 202. 203. 204. 205. 206. 207. 208. 209. 210.\n 211. 212. 213. 214. 215. 216. 217. 218. 219. 220. 221. 222. 223. 224.\n 225. 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237. 238.\n 239. 240. 241. 242. 243. 244. 245. 246. 247. 248. 249. 250. 251. 252.\n 253. 254. 255. 256. 257. 258. 259. 260. 261. 262. 263. 264. 265. 266.\n 267. 268. 269. 270. 271. 272. 273. 274. 275. 276. 277. 278. 279. 280.\n 281. 282. 283. 284. 285. 286. 287. 288. 289. 290. 291. 292. 293. 294.\n 295. 296. 297. 298. 299. 300. 301. 302. 303. 304. 305. 306. 307. 308.\n 309. 310. 311. 312. 313. 314. 315. 316. 317. 318. 319. 320. 321. 322.\n 323. 324. 325. 326. 327. 328. 329. 330. 331. 332. 333. 334. 335. 336.\n 337. 338. 339. 340. 341. 342. 343. 344. 345. 346. 347. 348. 349. 350.\n 351. 352. 353. 354. 355. 356. 357. 358. 359. 360. 361. 362. 363. 364.\n 365. 366. 367. 368. 369. 370. 371. 372. 373. 374. 375. 376. 377. 378.\n 379. 380. 381. 382. 383. 384. 385. 386. 387. 388. 389. 390. 391. 392.\n 393. 394. 395. 396. 397. 398. 399. 400. 401. 402. 403. 404. 405. 406.\n 407. 408. 409. 410. 411. 412. 413. 414. 415. 416. 417. 418. 419. 420.\n 421. 422. 423. 424. 425. 426. 427. 428. 429. 430. 431. 432. 433. 434.\n 435. 436. 437. 438. 439. 440. 441. 442. 443. 444. 445. 446. 447. 448.\n 449. 450. 451. 452. 453. 454. 455. 456. 457. 458. 459. 460. 461. 462.\n 463. 464. 465. 466. 467. 468. 469. 470. 471. 472. 473. 474. 475. 476.\n 477. 478. 479. 480. 481. 482. 483. 484. 485. 486. 487. 488. 489. 490.\n 491. 492. 493. 494. 495. 496. 497. 498. 499. 500. 501. 502. 503. 504.\n 505. 506. 507. 508. 509. 510. 511. 512. 513. 514. 515. 516. 517. 518.\n 519. 520. 521. 522. 523. 524. 525. 526. 527. 528. 529. 530. 531. 532.\n 533. 534. 535. 536. 537. 538. 539. 540. 541. 542. 543. 544. 545. 546.\n 547. 548. 549. 550. 551. 552. 553. 554. 555. 556. 557. 558. 559. 560.\n 561. 562. 563. 564. 565. 566. 567. 568. 569. 570. 571. 572. 573. 574.\n 575. 576. 577. 578. 579. 580. 581. 582. 583. 584. 585. 586. 587. 588.\n 589. 590. 591. 592. 593. 594. 595. 596. 597. 598. 599. 600. 601. 602.\n 603. 604. 605. 606. 607. 608. 609. 610. 611. 612. 613. 614. 615. 616.\n 617. 618. 619. 620. 621. 622. 623. 624. 625. 626. 627. 628. 629. 630.\n 631. 632. 633. 634. 635. 636. 637. 638. 639. 640. 641. 642. 643. 644.\n 645. 646. 647. 648. 649. 650. 651. 652. 653. 654. 655. 656. 657. 658.\n 659. 660. 661. 662. 663. 664. 665. 666. 667. 668. 669. 670. 671. 672.\n 673. 674. 675. 676. 677. 678. 679. 680. 681. 682. 683. 684. 685. 686.\n 687. 688. 689. 690. 691. 692. 693. 694. 695. 696. 697. 698. 699. 700.\n 701. 702. 703. 704. 705. 706. 707. 708. 709. 710. 711. 712. 713. 714.\n 715. 716. 717. 718. 719. 720. 721. 722. 723. 724. 725. 726. 727. 728.\n 729. 730. 731. 732. 733. 734. 735. 736. 737. 738. 739. 740. 741. 742.\n 743. 744. 745. 746. 747. 748. 749. 750. 751. 752. 753. 754. 755. 756.\n 757. 758. 759. 760. 761. 762. 763. 764. 765. 766. 767. 768. 769. 770.\n 771. 772. 773. 774. 775. 776. 777. 778. 779. 780. 781. 782. 783. 784.\n 785. 786. 787. 788. 789. 790. 791. 792. 793. 794. 795. 796. 797. 798.\n 799. 800. 801. 802. 803. 804. 805. 806. 807. 808. 809. 810. 811. 812.\n 813. 814. 815. 816. 817. 818. 819. 820. 821. 822. 823. 824. 825. 826.\n 827. 828. 829. 830. 831. 832. 833. 834. 835. 836. 837. 838. 839. 840.\n 841. 842. 843. 844. 845. 846. 847. 848. 849. 850. 851. 852. 853. 854.\n 855. 856. 857. 858. 859. 860. 861. 862. 863. 864. 865. 866. 867. 868.\n 869. 870. 871. 872. 873. 874. 875. 876. 877. 878. 879. 880. 881. 882.\n 883. 884. 885. 886. 887. 888. 889. 890. 891.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "features = train.columns[0]\n",
    "# features = ('PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Level')\n",
    "clf.fit(train[features], train['Survived'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (SimulationModelling)",
   "language": "python",
   "name": "pycharm-76950895"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
