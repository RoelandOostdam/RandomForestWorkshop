{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deel 2: Missing Values/Proximity Matrix\n",
    "Wat zijn de grote krachten van een randomforest? Dat het relatief minder uitmaakt als bij andere algoritmes dat de data schoon is. Hieronder gaan we een paar oefeningen doen om deze missende data zo goed mogelijk te interpreteren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import operator\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(630)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We laden hier de heart-disease dataset in, maar we verwijderen allerlei random data uit de dataset.<br>\n",
    "Wij gaan proberen om die waarden zo goed mogelijk in te vullen en een zo hoog mogelijke score te krijgen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df = pd.read_csv('heart.csv')\n",
    "# Train data wordt gemaakt voor verder gebruik\n",
    "X_mf = heart_df.drop('target', axis=1)\n",
    "y_mf = heart_df[['target']]\n",
    "X_mf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In de lijst <b>zeroedout</b> staan alle row indices en kolomnamen die uit de dataset gehaald zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroedout = []\n",
    "for i in range(int(X_mf.size * 0.3)):\n",
    "    row = random.randint(0, len(X_mf) - 1)\n",
    "    col = random.choice((X_mf).columns)\n",
    "    zeroedout.append((row, col))\n",
    "zeroedout[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laten we onze baseline zetten\n",
    "\n",
    "Hieronder veranderen we alle zeroedout cellen naar 0.<br>\n",
    "Daarna testen we welke score dit opleverd.<br>\n",
    "Dit levert een score op van <b>0.75</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=0)\n",
    "rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in zeroedout:\n",
    "    index = i[0] # Dit is de index van row die aangepast moet worden\n",
    "    col = i[1] # Dit is de kolomnaam van de row die aangepast moet worden\n",
    "    X_mf[col][index] = 0 # Je moet X_mf veranderen naar de correcte schattingswaarde (in dit geval alles naar 0)\n",
    "\n",
    "# Hieronder wordt de data gesplit en wordt het model gefit en gescored\n",
    "X_train_mf, X_test_mf, y_train_mf, y_test_mf = train_test_split(X_mf, y_mf, random_state=0)\n",
    "rfc.fit(X_train_mf, y_train_mf)\n",
    "rfc.score(X_test_mf, y_test_mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probeer nu hetzelfde, maar verander dan alle zeroedout data naar het gemiddelde, mediaan en de modus.<br>\n",
    "Laat vervolgens de score voor elke soort zien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over het algemeen is er nog een beter manier om een eerste schatting te maken, en dat is om het gemiddelde te pakken voor numerieke datapunten en de modus voor categoriale. Maar dan niet het gemiddelde en modus van de gehele dataset, maar van de datapunten met dezelfde target waarde.<br><br>\n",
    "\n",
    "De eerste stap is uitzoeken welke waarden categoriaal zijn. Zet deze in de lijst categorial_cols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorial_cols = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervolgens gaan we per zeroedoud datapunt kijken of het een categoriale waarde is.<br> Zo ja, pakken we de modus van alle waarden met target waarde. En zo nee, pakken we het gemiddelde van alle waarden met die target waarde.<br>\n",
    "Welke score komt er dan uit het model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in zeroedout:\n",
    "    index = i[0]\n",
    "    col = i[1]\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFC.apply\n",
    "Nu we schattingen hebben ingevuld kunnen we de randomforest toepassen op alle data.<br>\n",
    "Dit doen we met de apply functie. Deze functie geeft een lijst terug met per tree bij welke leaf nodes alle rows terecht komen.<br>\n",
    "Standaard bij deze dataset kiest sklearn ervoor om 100 bomen te gebruiken. Dit zie je terug bij de shape[1] van de apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves = rfc.apply(X_mf)\n",
    "print(leaves.shape)\n",
    "leaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Wanneer rows in dezelfde leaf node eindigen, definieren wij deze als soortgelijk.</b><br>\n",
    "Het is niet de bedoeling dat we hier met de hyperparameters gaan knoeien, omdat de proximity matrix dan sub-optimaal zou kunnen werken. Als er te weinig vergelijkbare rows zijn, is er vaak sprake van overfitting. Terwijl andersom vaak een teken is van underfitting. Maar dit is geen probleem met de standaard parameters.\n",
    "\n",
    "## Proximity Matrix\n",
    "We houden in een proximity matrix bij welke rows soortgelijk zijn aan anderen<br>\n",
    "Dus wanneer als voorbeeld regel 2 in dezelfde leaf node terecht komt als regel 3, Verhogen we deze cell met 1.<br>\n",
    "Een proximity matrix is altijd inverted hetzelfde. de x en y as zijn hieronder allebei de row index.<br>\n",
    "\n",
    "|   | 1 | 2 | 3 | 4 |\n",
    "|---|---|---|---|---|\n",
    "| 1 |   |   |   |   |\n",
    "| 2 |   |   | 1 |   |\n",
    "| 3 |   | 1 |   |   |\n",
    "| 4 |   |   |   |   |\n",
    "\n",
    "Optimaal zou zijn dat we maar een spiegelkant van de matrix zouden berekenen (en nog het liefst alleen de rows met missende data). Maar voor het programmeer gemak en duidelijkheid doen we ze allebei.\n",
    "\n",
    "De opdracht is om een matrix terug te geven die aangeeft tot hoeverre elke row gelijksoortig is aan elke andere row.<br>\n",
    "We doen dit door voor elke boom elke row met elke row te vergelijken en te kijken of deze in dezelfde leaf eindigt.\n",
    "\n",
    "Een goede indicatie of de matrix klopt, is het gegeven dat elke row altijd maximaal gelijksoortig is aan zichzelf.<br> Dit betekent dat er een diagonale lijn van linksboven naar rechtsonder aanwezig moet zijn.\n",
    "\n",
    "Ten slotte heeft de functie het argument \"normalize\". Wanneer deze True is, moeten alle proximities gedeeld door het aantal trees worden gedaan. Dit, zodat de hele matrix binnen de schaal van 0 (totaal verschillend) naar 1 (100% soortgelijk) valt. Om de laatste stap te doen (het toepassen van de matrix) moet de matrix eerst genormaliseerd zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proximityMatrix(model, X, normalize=True):\n",
    "     # Lijst met alle end nodes per row voor elke tree zoals hierboven uitgelegd.\n",
    "    leaves = model.apply(X)\n",
    "    \n",
    "    # Het aantal rows en trees in de dataset\n",
    "    n_rows = leaves.shape[0]\n",
    "    n_trees = leaves.shape[1]\n",
    "    \n",
    "    # De proximity matrix heeft een shape van NxN waar N het aantal rows zijn.\n",
    "    proximity_matrix = np.zeros([n_rows, n_rows])\n",
    "\n",
    "    for tree in leaves.T: # Voor elke boom\n",
    "        # TODO: Itereer door elke row in X, en itereer vervolgens weer door elke in X en kijk of ze \n",
    "        # allebei in dezelfde leaf node eindigen. Zo ja, increment de waarde in de proximity matrix cell dan met 1.\n",
    "        pass\n",
    "    return proximity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(proximityMatrix(rfc, X_mf, normalize=True))\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Het toepassen van de matrix\n",
    "Omdat wij denken dat het toepassen van de matrix te ingewikkeld is om binnen de scope van deze workshop te houden, hebben wij ervoor gekozen om de functie die de matrix toepast alvast in te vullen.\n",
    "\n",
    "Voor een duidelijke uitleg van wat er in deze functie gebeurt refereren we je naar de volgende zeer hulpzame [video](https://www.youtube.com/watch?v=sQ870aTKqiM).<br>\n",
    "Deze functie gebruikt de matrix functie van hierboven. Als deze niet/fout is gemaakt, produceert deze functie een error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mf, X_test_mf, y_train_mf, y_test_mf = train_test_split(X_mf, y_mf, random_state=0)\n",
    "rfc.fit(X_train_mf, y_train_mf)\n",
    "rfc.score(X_test_mf, y_test_mf)\n",
    "\n",
    "for redo in range(7):\n",
    "    \n",
    "    matrix = proximityMatrix(rfc, X_mf)\n",
    "    for coord in zeroedout:\n",
    "\n",
    "        new_value = 0\n",
    "        sum_of_weights = sum(matrix[i[0]])\n",
    "        weights = {}\n",
    "        \n",
    "        if i[1] in categorial_cols:  # categorical\n",
    "            \n",
    "            for value, freq in X_mf[coord[1]].value_counts(normalize=True).items():\n",
    "                weight = 0\n",
    "                \n",
    "                for index, j in enumerate(matrix[coord[0]]):\n",
    "                    if X_mf[coord[1]][index] == value:\n",
    "                        weight += j\n",
    "                        \n",
    "                weights[value] = freq * (weight / sum_of_weights)\n",
    "                \n",
    "            new_value = max(weights.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "        else:  # numerical\n",
    "        \n",
    "            for index, weight in enumerate(matrix[coord[0]]):\n",
    "                new_value += (weight / sum_of_weights) * X_mf[coord[1]][index]\n",
    "\n",
    "        X_mf[coord[1]][coord[0]] = new_value\n",
    "\n",
    "    X_train_mf, X_test_mf, y_train_mf, y_test_mf = train_test_split(X_mf, y_mf, random_state=0)\n",
    "    rfc.fit(X_train_mf, y_train_mf)\n",
    "    print(rfc.score(X_test_mf, y_test_mf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
